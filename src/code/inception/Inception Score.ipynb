{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from six.moves import range\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "dir_path = '/home/avoyd/GANtor-Arts-Center/src/code/main.py'\n",
    "sys.path.append(dir_path)\n",
    "sys.path.append('/home/avoyd/GANtor-Arts-Center/src/code/')\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torchfile\n",
    "\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "from miscc.utils import mkdir_p\n",
    "from miscc.utils import weights_init\n",
    "from miscc.utils import save_img_results, save_model\n",
    "from miscc.utils import KL_loss\n",
    "from miscc.utils import compute_discriminator_loss, compute_generator_loss\n",
    "\n",
    "from tensorboard import summary\n",
    "from tensorboardX import FileWriter\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch.utils.data\n",
    "\n",
    "from torchvision.models.inception import inception_v3\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import datetime\n",
    "import dateutil\n",
    "import dateutil.tz\n",
    "from PIL import Image\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from miscc.datasets import TextDataset\n",
    "from miscc.utils import mkdir_p\n",
    "from trainer import GANTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from:  ../../../results/wikiart_stageII_2019_05_15_03_54_54/Model/netG_epoch_45.pth\n",
      "Load from:  ../../../results/wikiart_stageI_2019_05_14_23_03_43/Model/netG_epoch_60.pth\n",
      "STAGE2_G(\n",
      "  (STAGE1_G): STAGE1_G(\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=127, out_features=24576, bias=False)\n",
      "      (1): BatchNorm1d(24576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (upsample1): Sequential(\n",
      "      (0): Upsample(scale_factor=2, mode=nearest)\n",
      "      (1): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace)\n",
      "    )\n",
      "    (upsample2): Sequential(\n",
      "      (0): Upsample(scale_factor=2, mode=nearest)\n",
      "      (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace)\n",
      "    )\n",
      "    (upsample3): Sequential(\n",
      "      (0): Upsample(scale_factor=2, mode=nearest)\n",
      "      (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace)\n",
      "    )\n",
      "    (upsample4): Sequential(\n",
      "      (0): Upsample(scale_factor=2, mode=nearest)\n",
      "      (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace)\n",
      "    )\n",
      "    (img): Sequential(\n",
      "      (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(3, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(192, 384, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Conv2d(384, 768, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace)\n",
      "  )\n",
      "  (hr_joint): Sequential(\n",
      "    (0): Conv2d(795, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (residual): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (upsample1): Sequential(\n",
      "    (0): Upsample(scale_factor=2, mode=nearest)\n",
      "    (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace)\n",
      "  )\n",
      "  (upsample2): Sequential(\n",
      "    (0): Upsample(scale_factor=2, mode=nearest)\n",
      "    (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace)\n",
      "  )\n",
      "  (upsample3): Sequential(\n",
      "    (0): Upsample(scale_factor=2, mode=nearest)\n",
      "    (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace)\n",
      "  )\n",
      "  (upsample4): Sequential(\n",
      "    (0): Upsample(scale_factor=2, mode=nearest)\n",
      "    (1): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace)\n",
      "  )\n",
      "  (img): Sequential(\n",
      "    (0): Conv2d(48, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cfg_from_file('../cfg/wikiart_s2.yml')\n",
    "\n",
    "from model import STAGE1_G, STAGE2_G, STAGE2_D\n",
    "\n",
    "Stage1_G = STAGE1_G()\n",
    "\n",
    "netG = STAGE2_G(Stage1_G)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "stage_1_file = '../../../results/wikiart_stageI_2019_05_14_23_03_43/Model/netG_epoch_60.pth'\n",
    "stage_2_file = '../../../results/wikiart_stageII_2019_05_15_03_54_54/Model/netG_epoch_45.pth'\n",
    "\n",
    "state_dict = torch.load(stage_2_file, map_location=lambda storage, loc: storage)\n",
    "netG.load_state_dict(state_dict)\n",
    "print('Load from: ', stage_2_file)\n",
    "\n",
    "state_dict = torch.load(stage_1_file,map_location=lambda storage, loc: storage)\n",
    "netG.STAGE1_G.load_state_dict(state_dict)\n",
    "print('Load from: ', stage_1_file)\n",
    "\n",
    "if cfg.CUDA:\n",
    "    netG.cuda()\n",
    "\n",
    "print(netG)\n",
    "with torch.no_grad():\n",
    "    netG = netG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    }
   ],
   "source": [
    "#image_dir = './Test Outputs/Midpoint Outputs'\n",
    "\n",
    "nz = 100\n",
    "batch_size = 16\n",
    "embedding_size = 27\n",
    "\n",
    "for i in range(0, embedding_size):\n",
    "    noise = Variable(torch.FloatTensor(batch_size, nz))\n",
    "    with torch.no_grad():\n",
    "                fixed_noise = \\\n",
    "                    Variable(torch.FloatTensor(batch_size, nz).normal_(0, 1))\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "\n",
    "    noise.data.normal_(0, 1)\n",
    "    text_embeddings = torch.zeros((batch_size, embedding_size))\n",
    "    text_embeddings[:, i] = 1\n",
    "\n",
    "    inputs = (text_embeddings, noise)\n",
    "\n",
    "    lr_fake, fake = nn.parallel.data_parallel(netG, inputs, [0])\n",
    "\n",
    "    vutils.save_image(\n",
    "                fake.data, '%s/fake_samples_cat_%i.png' %\n",
    "                (image_dir, i), normalize=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_score(imgs, cuda=True, batch_size=32, resize=False, splits=1):\n",
    "    \"\"\"Computes the inception score of the generated images imgs\n",
    "    imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n",
    "    cuda -- whether or not to run on GPU\n",
    "    batch_size -- batch size for feeding into Inception v3\n",
    "    splits -- number of splits\n",
    "    \"\"\"\n",
    "    N = len(imgs)\n",
    "\n",
    "    assert batch_size > 0\n",
    "    assert N > batch_size\n",
    "\n",
    "    # Set up dtype\n",
    "    if cuda:\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"WARNING: You have a CUDA device, so you should probably set cuda=True\")\n",
    "        dtype = torch.FloatTensor\n",
    "\n",
    "    # Set up dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n",
    "\n",
    "    # Load inception model\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).type(dtype)\n",
    "    inception_model.eval();\n",
    "    up = nn.Upsample(size=(256, 256), mode='bilinear').type(dtype)\n",
    "    def get_pred(x):\n",
    "        if resize:\n",
    "            x = up(x)\n",
    "        x = inception_model(x)\n",
    "        return F.softmax(x).data.cpu().numpy()\n",
    "\n",
    "    # Get predictions\n",
    "    preds = np.zeros((N, 1000))\n",
    "\n",
    "    for i, batch in enumerate(dataloader, 0):\n",
    "        batch = batch.type(dtype)\n",
    "        batchv = Variable(batch)\n",
    "        batch_size_i = batch.size()[0]\n",
    "\n",
    "        preds[i*batch_size:i*batch_size + batch_size_i] = get_pred(batchv)\n",
    "\n",
    "    # Now compute the mean kl-div\n",
    "    split_scores = []\n",
    "\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
    "        py = np.mean(part, axis=0)\n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]\n",
    "            scores.append(entropy(pyx, py))\n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#     class IgnoreLabelDataset(torch.utils.data.Dataset):\n",
    "#         def __init__(self, orig):\n",
    "#             self.orig = orig\n",
    "\n",
    "#         def __getitem__(self, index):\n",
    "#             return self.orig[index][0]\n",
    "\n",
    "#         def __len__(self):\n",
    "#             return len(self.orig)\n",
    "\n",
    "# #     cifar = dset.CIFAR10(root='data/', download=True,\n",
    "# #                              transform=transforms.Compose([\n",
    "# #                                  transforms.Scale(32),\n",
    "# #                                  transforms.ToTensor(),\n",
    "# #                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "# #                              ])\n",
    "#     )\n",
    "\n",
    "    image_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(cfg.IMSIZE),\n",
    "            \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    wikiart_dataset = TextDataset(cfg.DATA_DIR, split='train',\n",
    "                      imsize=cfg.IMSIZE,\n",
    "                      transform=image_transform)\n",
    "\n",
    "print(cfg.IMSIZE)\n",
    "\n",
    "num_gpu = 1\n",
    "\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=cfg.TRAIN.BATCH_SIZE * num_gpu,\n",
    "    drop_last=True, shuffle=True, num_workers=int(cfg.WORKERS))\n",
    "\n",
    "\n",
    "    print (\"Calculating Inception Score...\")\n",
    "    print (inception_score(wikiart_dataset, cuda=True, batch_size=32, resize=True, splits=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
