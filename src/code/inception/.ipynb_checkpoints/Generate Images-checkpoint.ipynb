{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'miscc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bd5af5d7c591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmiscc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_from_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmiscc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmkdir_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmiscc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mweights_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'miscc'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from six.moves import range\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "# dir_path = '~/GANtor-Arts-Center/src/code/main.py'\n",
    "sys.path.append(dir_path)\n",
    "sys.path.append('~/GANtor-Arts-Center/src/code/')\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torchfile\n",
    "\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "from miscc.utils import mkdir_p\n",
    "from miscc.utils import weights_init\n",
    "from miscc.utils import save_img_results, save_model\n",
    "from miscc.utils import KL_loss\n",
    "from miscc.utils import compute_discriminator_loss, compute_generator_loss\n",
    "\n",
    "from tensorboard import summary\n",
    "from tensorboardX import FileWriter\n",
    "\n",
    "import torchvision.utils as vutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(0)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from:  ../../../results/wikiart_stageI_2019_05_14_23_03_43/Model/netG_epoch_60.pth\n",
      "STAGE1_G(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=127, out_features=24576, bias=False)\n",
      "    (1): BatchNorm1d(24576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (upsample1): Sequential(\n",
      "    (0): Upsample(scale_factor=2, mode=nearest)\n",
      "    (1): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace)\n",
      "  )\n",
      "  (upsample2): Sequential(\n",
      "    (0): Upsample(scale_factor=2, mode=nearest)\n",
      "    (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace)\n",
      "  )\n",
      "  (upsample3): Sequential(\n",
      "    (0): Upsample(scale_factor=2, mode=nearest)\n",
      "    (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace)\n",
      "  )\n",
      "  (upsample4): Sequential(\n",
      "    (0): Upsample(scale_factor=2, mode=nearest)\n",
      "    (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace)\n",
      "  )\n",
      "  (img): Sequential(\n",
      "    (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import STAGE1_G, STAGE2_G, STAGE2_D\n",
    "\n",
    "\n",
    "stage = 1\n",
    "category = \"style\"\n",
    "image_size = 64 if stage == 1 else 256\n",
    "image_dir = './baseline_generated/{}{}/'.format(category, image_size)\n",
    "\n",
    "style_1 = '../../../results/wikiart_stageI_2019_05_14_23_03_43/Model/netG_epoch_60.pth'\n",
    "style_2 = '../../../results/wikiart_stageII_2019_05_15_03_54_54/Model/netG_epoch_45.pth'\n",
    "\n",
    "genre_1 = \"../../saved_models/stage1_genre/netG_epoch_70.pth\"\n",
    "genre_2 = \"\"\n",
    "\n",
    "config_file = '../cfg/wikiart_s2_style.yml' if category == \"style\" else '../cfg/wikiart_s2.yml'\n",
    "cfg_from_file(config_file)\n",
    "\n",
    "Stage1_G = STAGE1_G()\n",
    "\n",
    "stage_1_file = genre_1 if category == \"genre\" else style_1\n",
    "stage_2_file = genre_2 if category == \"genre\" else style_2\n",
    "\n",
    "if stage == 1:\n",
    "    netG = Stage1_G\n",
    "    state_dict = torch.load(stage_1_file,map_location=lambda storage, loc: storage)\n",
    "    netG.load_state_dict(state_dict)\n",
    "    print('Load from: ', stage_1_file)\n",
    "    \n",
    "elif stage == 2:\n",
    "    netG = STAGE2_G(Stage1_G)\n",
    "    state_dict = torch.load(stage_1_file,map_location=lambda storage, loc: storage)\n",
    "    netG.STAGE1_G.load_state_dict(state_dict)\n",
    "    print('Load from: ', stage_1_file)\n",
    "    state_dict = torch.load(stage_2_file, map_location=lambda storage, loc: storage)\n",
    "    netG.load_state_dict(state_dict)\n",
    "    print('Load from: ', stage_2_file)\n",
    "\n",
    "else:\n",
    "    raise Exception (\"Stage unspecified!\")\n",
    "    \n",
    "netG.eval()\n",
    "\n",
    "if cfg.CUDA:\n",
    "    netG.cuda()\n",
    "\n",
    "print(netG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter num 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter num 1\n",
      "Iter num 2\n",
      "Iter num 3\n",
      "Iter num 4\n",
      "Iter num 5\n",
      "Iter num 6\n",
      "Iter num 7\n",
      "Iter num 8\n",
      "Iter num 9\n",
      "Iter num 10\n",
      "Iter num 11\n",
      "Iter num 12\n",
      "Iter num 13\n",
      "Iter num 14\n",
      "Iter num 15\n",
      "Iter num 16\n",
      "Iter num 17\n",
      "Iter num 18\n",
      "Iter num 19\n",
      "Iter num 20\n",
      "Iter num 21\n",
      "Iter num 22\n",
      "Iter num 23\n",
      "Iter num 24\n",
      "Iter num 25\n",
      "Iter num 26\n",
      "Iter num 27\n",
      "Iter num 28\n",
      "Iter num 29\n",
      "Iter num 30\n",
      "Iter num 31\n",
      "Iter num 32\n",
      "Iter num 33\n",
      "Iter num 34\n",
      "Iter num 35\n",
      "Iter num 36\n",
      "Iter num 37\n",
      "Iter num 38\n",
      "Iter num 39\n",
      "Iter num 40\n",
      "Iter num 41\n",
      "Iter num 42\n",
      "Iter num 43\n",
      "Iter num 44\n",
      "Iter num 45\n",
      "Iter num 46\n",
      "Iter num 47\n",
      "Iter num 48\n",
      "Iter num 49\n",
      "Iter num 50\n",
      "Iter num 51\n",
      "Iter num 52\n",
      "Iter num 53\n",
      "Iter num 54\n",
      "Iter num 55\n",
      "Iter num 56\n",
      "Iter num 57\n",
      "Iter num 58\n",
      "Iter num 59\n",
      "Iter num 60\n",
      "Iter num 61\n",
      "Iter num 62\n",
      "Iter num 63\n",
      "Iter num 64\n",
      "Iter num 65\n",
      "Iter num 66\n",
      "Iter num 67\n",
      "Iter num 68\n",
      "Iter num 69\n",
      "Iter num 70\n",
      "Iter num 71\n",
      "Iter num 72\n",
      "Iter num 73\n",
      "Iter num 74\n",
      "Iter num 75\n",
      "Iter num 76\n",
      "Iter num 77\n",
      "Iter num 78\n",
      "Iter num 79\n",
      "Iter num 80\n",
      "Iter num 81\n",
      "Iter num 82\n",
      "Iter num 83\n",
      "Iter num 84\n",
      "Iter num 85\n",
      "Iter num 86\n",
      "Iter num 87\n",
      "Iter num 88\n",
      "Iter num 89\n",
      "Iter num 90\n",
      "Iter num 91\n",
      "Iter num 92\n",
      "Iter num 93\n",
      "Iter num 94\n",
      "Iter num 95\n",
      "Iter num 96\n",
      "Iter num 97\n",
      "Iter num 98\n",
      "Iter num 99\n"
     ]
    }
   ],
   "source": [
    "nz = 100\n",
    "batch_size = 16\n",
    "embedding_size = 27 if category == \"style\" else 10\n",
    "num_iters = 100 if category == \"style\" else 300 #43.2k images for style, 48k for genre\n",
    "\n",
    "for i in range(num_iters):\n",
    "    print (\"Iter num %i\"%(i))\n",
    "    for class_idx in range(embedding_size):\n",
    "        noise = Variable(torch.FloatTensor(batch_size, nz))\n",
    "        with torch.no_grad():\n",
    "                    fixed_noise = \\\n",
    "                        Variable(torch.FloatTensor(batch_size, nz).normal_(0, 1))\n",
    "        noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "\n",
    "        noise.data.normal_(0, 1)\n",
    "        text_embeddings = torch.zeros((batch_size, embedding_size)).cuda()\n",
    "        text_embeddings[:, class_idx] = 1\n",
    "\n",
    "#         inputs = (text_embeddings, noise)\n",
    "\n",
    "        lr_fake, fake = netG(text_embeddings, noise)\n",
    "\n",
    "        for im_idx, im in enumerate(fake.data):\n",
    "            \n",
    "            vutils.save_image(\n",
    "                        im, '%s%i/%i_%i.png' %\n",
    "                        (image_dir, class_idx, i, im_idx), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
