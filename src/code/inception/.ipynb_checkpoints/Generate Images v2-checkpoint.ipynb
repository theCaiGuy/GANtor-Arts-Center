{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from six.moves import range\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "# dir_path = '~/GANtor-Arts-Center/src/code/main.py'\n",
    "# sys.path.append(dir_path)\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torchfile\n",
    "\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "from miscc.utils import mkdir_p\n",
    "from miscc.utils import weights_init\n",
    "from miscc.utils import save_img_results, save_model\n",
    "from miscc.utils import KL_loss\n",
    "from miscc.utils import compute_discriminator_loss, compute_generator_loss\n",
    "\n",
    "from tensorboard import summary\n",
    "from tensorboardX import FileWriter\n",
    "\n",
    "import torchvision.utils as vutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(0)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../miscc/config.py:99: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from:  ../../saved_models/v2/s1_genre/netG_epoch_90.pth\n",
      "Load from:  ../../saved_models/v2/s2_genre/netG_epoch_70.pth\n",
      "DataParallel(\n",
      "  (module): STAGE2_G(\n",
      "    (STAGE1_G): STAGE1_G(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=110, out_features=24576, bias=False)\n",
      "        (1): BatchNorm1d(24576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (upsample1): Sequential(\n",
      "        (0): Upsample(scale_factor=2, mode=nearest)\n",
      "        (1): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (upsample2): Sequential(\n",
      "        (0): Upsample(scale_factor=2, mode=nearest)\n",
      "        (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (upsample3): Sequential(\n",
      "        (0): Upsample(scale_factor=2, mode=nearest)\n",
      "        (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (upsample4): Sequential(\n",
      "        (0): Upsample(scale_factor=2, mode=nearest)\n",
      "        (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (img): Sequential(\n",
      "        (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (encoder): Sequential(\n",
      "      (0): Conv2d(3, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): LeakyReLU(negative_slope=0.2)\n",
      "      (2): Conv2d(192, 384, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): LeakyReLU(negative_slope=0.2)\n",
      "      (5): Conv2d(384, 768, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (hr_joint): Sequential(\n",
      "      (0): Conv2d(778, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (residual): Sequential(\n",
      "      (0): ResBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace)\n",
      "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (1): ResBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace)\n",
      "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (upsample1): Sequential(\n",
      "      (0): Upsample(scale_factor=2, mode=nearest)\n",
      "      (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (upsample2): Sequential(\n",
      "      (0): Upsample(scale_factor=2, mode=nearest)\n",
      "      (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (upsample3): Sequential(\n",
      "      (0): Upsample(scale_factor=2, mode=nearest)\n",
      "      (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (upsample4): Sequential(\n",
      "      (0): Upsample(scale_factor=2, mode=nearest)\n",
      "      (1): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (img): Sequential(\n",
      "      (0): Conv2d(48, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from modelv2 import STAGE1_G, STAGE2_G, STAGE2_D\n",
    "\n",
    "# Only classified on genre for GANtor-v2\n",
    "category = \"genre\"\n",
    "\n",
    "stage = 2\n",
    "image_size = 64 if stage == 1 else 256\n",
    "image_dir = './v2_generated/{}{}/'.format(category, image_size)\n",
    "\n",
    "style_1 = ''\n",
    "style_2 = ''\n",
    "\n",
    "genre_1 = \"../../saved_models/v2/s1_genre/netG_epoch_90.pth\"\n",
    "genre_2 = \"../../saved_models/v2/s2_genre/netG_epoch_70.pth\"\n",
    "\n",
    "config_file = '../cfg/wikiart_s2_v2.yml'\n",
    "cfg_from_file(config_file)\n",
    "\n",
    "Stage1_G = STAGE1_G()\n",
    "\n",
    "stage_1_file = genre_1 if category == \"genre\" else style_1\n",
    "stage_2_file = genre_2 if category == \"genre\" else style_2\n",
    "\n",
    "if stage == 1:\n",
    "    netG = Stage1_G\n",
    "    state_dict = torch.load(stage_1_file,map_location=lambda storage, loc: storage)\n",
    "    netG.load_state_dict(state_dict)\n",
    "    print('Load from: ', stage_1_file)\n",
    "    \n",
    "elif stage == 2:\n",
    "    netG = STAGE2_G(Stage1_G)\n",
    "    state_dict = torch.load(stage_1_file,map_location=lambda storage, loc: storage)\n",
    "    netG.STAGE1_G.load_state_dict(state_dict)\n",
    "    print('Load from: ', stage_1_file)\n",
    "    state_dict = torch.load(stage_2_file, map_location=lambda storage, loc: storage)\n",
    "    netG.load_state_dict(state_dict)\n",
    "    print('Load from: ', stage_2_file)\n",
    "\n",
    "else:\n",
    "    raise Exception (\"Stage unspecified!\")\n",
    "    \n",
    "# netG.eval()\n",
    "\n",
    "if cfg.CUDA:\n",
    "    netG.cuda()\n",
    "    netG = nn.DataParallel(netG)\n",
    "\n",
    "print(netG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter num 0\n",
      "Iter num 1\n",
      "Iter num 2\n",
      "Iter num 3\n",
      "Iter num 4\n",
      "Iter num 5\n",
      "Iter num 6\n",
      "Iter num 7\n",
      "Iter num 8\n",
      "Iter num 9\n",
      "Iter num 10\n",
      "Iter num 11\n",
      "Iter num 12\n",
      "Iter num 13\n",
      "Iter num 14\n",
      "Iter num 15\n",
      "Iter num 16\n",
      "Iter num 17\n",
      "Iter num 18\n",
      "Iter num 19\n",
      "Iter num 20\n",
      "Iter num 21\n",
      "Iter num 22\n",
      "Iter num 23\n",
      "Iter num 24\n",
      "Iter num 25\n",
      "Iter num 26\n",
      "Iter num 27\n",
      "Iter num 28\n",
      "Iter num 29\n",
      "Iter num 30\n",
      "Iter num 31\n",
      "Iter num 32\n",
      "Iter num 33\n"
     ]
    }
   ],
   "source": [
    "nz = 100\n",
    "batch_size = 64\n",
    "embedding_size = 27 if category == \"style\" else 10\n",
    "num_iters = 100 # 51.2k\n",
    "\n",
    "for i in range(0, num_iters):\n",
    "    print (\"Iter num %i\"%(i))\n",
    "    for class_idx in range(embedding_size):\n",
    "        noise = Variable(torch.FloatTensor(batch_size, nz))\n",
    "        with torch.no_grad():\n",
    "                    fixed_noise = \\\n",
    "                        Variable(torch.FloatTensor(batch_size, nz).normal_(0, 1))\n",
    "        noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "\n",
    "        noise.data.normal_(0, 1)\n",
    "        text_embeddings = torch.zeros((batch_size, embedding_size)).cuda()\n",
    "        text_embeddings[:, class_idx] = 1\n",
    "\n",
    "#         inputs = (text_embeddings, noise)\n",
    "        with torch.no_grad():\n",
    "            lr_fake, fake = netG(text_embeddings, noise)\n",
    "\n",
    "        for im_idx, im in enumerate(fake.data):\n",
    "            \n",
    "            vutils.save_image(\n",
    "                        im, '%s%i/%i_%i.png' %\n",
    "                        (image_dir, class_idx, i, im_idx), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
